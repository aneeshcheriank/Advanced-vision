{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "impacat of Data Augmentation and Batch Normalization",
      "provenance": [],
      "private_outputs": true,
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOZ5+Lw71h8G76sLTHlPZa5",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/aneeshcheriank/Advanced-vision/blob/main/impacat_of_Data_Augmentation_and_Batch_Normalization.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Conditions\n",
        "- No Batch normalization & No Data Augmentation\n",
        "- Batch normalization & No Data Augmentation\n",
        "- Batch normalization & Data Augmenation"
      ],
      "metadata": {
        "id": "eKGl-KCmMqXI"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OkM7Mx6qMbtd"
      },
      "outputs": [],
      "source": [
        "# required packages\n",
        "import torch\n",
        "import torchvision\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torchvision import transforms, models, datasets\n",
        "\n",
        "!pip install torch_summary\n",
        "from torchsummary import summary\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "print(device)\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image # what is the use of PIL.image?\n",
        "import cv2, glob, numpy as np, pandas as pd\n",
        "from glob import glob\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from tqdm import tqdm"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# download the dataset\n",
        "!pip install -q kaggle\n",
        "from google.colab import files\n",
        "files.upload()\n",
        "# upload the kaggle authentication token \n",
        "# to download the data\n",
        "!mkdir -p ~/.kaggle\n",
        "!cp kaggle.json ~/.kaggle/\n",
        "!ls ~/.kaggle\n",
        "!chmod 600 ~/.kaggle/kaggle.json"
      ],
      "metadata": {
        "id": "4cwC254sRf4F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# download and unzip the file\n",
        "!kaggle competitions download -c dogs-vs-cats\n",
        "!unzip dogs-vs-cats.zip\n",
        "!unzip -q train.zip -d data\n",
        "!unzip -q test1.zip -d data"
      ],
      "metadata": {
        "id": "HLaUjNslUums"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define transforms on the data\n",
        "from torchvision import transforms as T\n",
        "trn_tfms = T.Compose([\n",
        "  T.ToPILImage(),\n",
        "  T.Resize(224),\n",
        "  T.CenterCrop(224),\n",
        "  T.ColorJitter(brightness=(0.8, 1.2),\n",
        "    contrast=(0.8, 1.2),\n",
        "    saturation=(0.8, 1.2),\n",
        "    hue=0.25\n",
        "  ),\n",
        "  T.RandomAffine(5, translate=(0.01, 0.1)),\n",
        "  T.ToTensor(),\n",
        "  T.Normalize(mean=(.45, .44, .43),\n",
        "              std=(0.22, 0.23, 0.24)\n",
        "              )\n",
        "  ])\n",
        "\n",
        "val_tfms = T.Compose([\n",
        "  T.ToPILImage(),\n",
        "  T.Resize(32),\n",
        "  T.CenterCrop(32),\n",
        "  T.ToTensor(),\n",
        "  T.Normalize(mean=(.45, .44, .43),\n",
        "              std=(0.22, 0.23, 0.24)\n",
        "              )\n",
        "  ])"
      ],
      "metadata": {
        "id": "8WtlDIrv-WJm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data_dir = 'data/train'\n",
        "test_data_dir = 'data/train'\n",
        "\n",
        "class CatsDogs(Dataset):\n",
        "  def __init__(self, folder, transform=None):\n",
        "    cats = glob(folder+'/cat.*.jpg')\n",
        "    dogs = glob(folder+'/dog.*.jpg')\n",
        "    self.fpaths = cats + dogs\n",
        "    \n",
        "    self.transform = transform\n",
        "    from random import shuffle, seed\n",
        "    seed(10)\n",
        "    shuffle(self.fpaths)\n",
        "    # target: name with cat is True else False\n",
        "    # print(self.fpaths[0])\n",
        "    self.targets = [fpath.split('/')[2].split('.')[0] == 'cat'\\\n",
        "      for fpath in self.fpaths]\n",
        "  \n",
        "  def __getitem__(self, ix):\n",
        "    f = self.fpaths[ix]\n",
        "    target = int(self.targets[ix])\n",
        "    # convert the targets to tensor\n",
        "    target = torch.tensor(target)\n",
        "    im = (cv2.imread(f)) # need to change the image from BGR to RBG\n",
        "    im = cv2.cvtColor(im, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "    return im, target\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.fpaths)\n",
        "\n",
        "  def collate_fn(self, batch):\n",
        "    imgs, cls = list(zip(*batch))\n",
        "    cls = torch.tensor(cls).float()\n",
        "    if self.transform:\n",
        "      imgs = [self.transform(img)[None, :, :, :] for img in imgs]\n",
        "    imgs = torch.cat(imgs)\n",
        "    imgs = imgs.float()\n",
        "    return imgs, cls\n",
        "\n",
        "\n",
        "# fetch the images and their labels\n",
        "data = CatsDogs(train_data_dir)\n",
        "\n",
        "im, label = data[200]\n",
        "plt.imshow(im)\n",
        "print(label)"
      ],
      "metadata": {
        "id": "evcK1ipOX-Gm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dt = CatsDogs(train_data_dir, trn_tfms)\n",
        "train_dl = DataLoader(\n",
        "  train_dt, batch_size = 128, shuffle=True, \n",
        "  collate_fn = train_dt.collate_fn, drop_last=True\n",
        ")\n",
        "\n",
        "# test data loader\n",
        "val_dt = CatsDogs(train_data_dir, val_tfms)\n",
        "val_dl = DataLoader(\n",
        "  val_dt, batch_size = 128, shuffle=False, collate_fn = train_dt.collate_fn, \n",
        "  drop_last=True\n",
        ")\n",
        "\n",
        "# to test the data loader\n",
        "imgs, labels = next(iter(train_dl))\n",
        "plt.figure(figsize=(4, 4))\n",
        "plt.imshow(imgs[0].permute(2, 1, 0))\n",
        "plt.axis(False)\n",
        "plt.show()\n",
        "# will through an error, since the normalized image +ve and -ve laues"
      ],
      "metadata": {
        "id": "bscUy5FXUF_-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def convBlock(ni, no):\n",
        "  return nn.Sequential(\n",
        "      nn.Dropout(0.2),\n",
        "      nn.Conv2d(ni, no, 3, padding = 1),\n",
        "      nn.ReLU(inplace=True),\n",
        "      nn.BatchNorm2d(no),\n",
        "      nn.MaxPool2d(2)\n",
        "  )\n",
        "\n",
        "class Classifier(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(Classifier, self).__init__()\n",
        "    self.model = nn.Sequential(\n",
        "        convBlock(3, 64),\n",
        "        convBlock(64, 64),\n",
        "        convBlock(64, 128),\n",
        "        convBlock(128, 256),\n",
        "        nn.Flatten(),\n",
        "        nn.Linear(14*14*256, 256),\n",
        "        nn.Dropout(0.2),\n",
        "        nn.ReLU(inplace=True),\n",
        "        nn.Linear(256, 1),\n",
        "        nn.Sigmoid()\n",
        "    )\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = self.model(x)\n",
        "    return x\n",
        "\n",
        "model = Classifier()\n",
        "loss_fn = nn.BCELoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.0001)\n",
        "\n",
        "# define a fucntion to train and evaluate the model on a batch\n",
        "def train_batch(data, model, optimizer, criterion):\n",
        "  model.train()\n",
        "  ims, labels = data\n",
        "  ims = ims.to(device)\n",
        "  labels = labels.to(device)\n",
        "  pred = model(ims)\n",
        "  loss = criterion(pred, labels[:, None])\n",
        "  loss.backward()\n",
        "  optimizer.step()\n",
        "  optimizer.zero_grad()\n",
        "  # calculate accuracy\n",
        "  pred_label = torch.argmax(pred, -1)\n",
        "  acc = ((pred_label > 0.5) == label).sum()/len(pred_label)\n",
        "\n",
        "  return loss.item(), acc.item()\n",
        "\n",
        "@torch.no_grad()\n",
        "def validate_batch(data, model, criterion):\n",
        "  model.eval()\n",
        "  ims, label = data\n",
        "  ims = ims.to(device)\n",
        "  label = label.to(device)\n",
        "  pred = model(ims)\n",
        "  loss = criterion(pred, label[:, None])\n",
        "  # calculate accuracy\n",
        "  pred_label = torch.argmax(pred, -1)\n",
        "  acc = ((pred_label > 0.5) == label).sum()/len(pred_label)\n",
        "\n",
        "  return loss.item(), acc.item()"
      ],
      "metadata": {
        "id": "1oSN3YR0cCT4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# training loop\n",
        "model = Classifier().to(device)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
        "n_epochs = 50\n",
        "\n",
        "train_losses, train_accs, val_losses, val_accs = [], [], [], []\n",
        "for epoch in tqdm(range(n_epochs)):\n",
        "  print(f'epoch: {epoch+1}/{n_epochs}')\n",
        "  batch_loss, batch_acc = [], []\n",
        "  for batch, data in enumerate(train_dl):\n",
        "    loss, acc = train_batch(data, model, optimizer, loss_fn)\n",
        "    # append the batch metrics\n",
        "    batch_loss.append(loss)\n",
        "    batch_acc.append(acc)\n",
        "  \n",
        "  batch_val_loss, batch_val_acc = [], []\n",
        "  for batch, data in enumerate(val_dl):\n",
        "    loss, acc = validate_batch(data, model, loss_fn)\n",
        "    # append the validation batch metrics\n",
        "    batch_val_loss.append(loss)\n",
        "    batch_val_acc.append(acc)\n",
        "  \n",
        "  train_loss = np.mean(batch_loss)\n",
        "  train_acc = np.mean(batch_acc)\n",
        "  val_loss = np.mean(batch_val_loss)\n",
        "  val_acc = np.mean(batch_val_acc)\n",
        "\n",
        "  # append the metics\n",
        "  train_losses.append(train_loss)\n",
        "  train_accs.append(train_accs)\n",
        "  val_losses.append(val_losses)\n",
        "  val_accs.append(val_acc)\n",
        "\n",
        "  print(f'train loss: {train_loss}; train acc: {train_acc}; validation loss: {val_loss}; validation acc: {val_acc}')"
      ],
      "metadata": {
        "id": "4WFGWzOtKsOn"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}